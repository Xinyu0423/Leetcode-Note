## 算法岗面经

### 面试问题
1. python的列表和元组的区别
   1. 元组和列表最大的区别就是，列表中的元素可以进行任意修改。而元组中的元素无法修改。
2. batchNorm的区别
   1. BatchNorm： 对一个batch-size样本内的每个特征做归一化
   2. LayerNorm： 针对每条样本，对每条样本的所有特征做归一化
   3. 简单举例：
      1. 假设现在有个二维矩阵：行代表batch-size， 列表示样本特征
      2. BatchNorm就是对这个二维矩阵中每一列的特征做归一化，也就是竖着做归一化
      3. LayerNorm就是对这个二维矩阵中每一行数据做归一化
   4. 相同点： 都是在深度学习中让当前层的参数稳定下来，避免梯度消失或者梯度爆炸，方便后面的继续学习
   5. 不同点：
      1. 如果你的特征依赖不同样本的统计参数，那BatchNorm更有效， 因为它不考虑不同特征之间的大小关系，但是保留不同样本间的大小关系
      2. Nlp领域适合用LayerNorm， CV适合BatchNorm，
      3. 对于Nlp来说，它不考虑不同样本间的大小关系，保留样本内不同特征之间的大小关系
3. BN、LN、IN、GN的区别和应用场景。
   1. Batch Normalization（BN）
      1. 解决Internal Covariate Shift问题：训练深层网络时，层内神经元间、层间神经元间激活值的量级差别较大，不满足iit独立同分布时，模型不稳定不容易收敛（直观来看解决方案要么自适应地调节每一层甚至每一个神经元的学习率，要么把神经元激活值规范化一下）。
      2. 缓解过拟合：深层网络容易过拟合，有时候dropout可能也解决不了。
      3. BN的缺点
         1. BN操作的效果受batchsize影响很大，如果batchsize较小，每次训练计算的均值方差不具有代表性且不稳定，甚至使模型效果恶化。
         2. BN很难用在RNN这种序列模型中，且效果不好
         3. 这一点算是BN的特点不能算是其缺点：训练和测试的BN参数是不同的
   2. Layer Normalization（LN）
      1. 层规范化LayerNormalization，LN是对当前隐藏层整层的神经元进行规范化
      2. LN VS BN：
         1. 对于[B,C,W,H]这样的训练数据而言，BN是在B,W,H维度求均值方差进行规范化，而LN是对C,W,H维度求均值方差进行规范化（当前层一共会求batchsize个均值和方差，每个batchsize分别规范化）
         2. 这样LN就与batchsize无关了，小的batchsize也可以进行归一化训练，LN也可以很轻松地用到RNN中。
         3. 总结
            1. LN与batchsize无关，在小batchsize上效果可能会比BN好，但是大batchsize的话还是BN效果好。
            2. LN可以轻松用到RNN上，且效果还不错
   3. Instance Normalization（IN）
      1. BN注重对batchsize数据归一化，但是在图像风格化任务中，生成的风格结果主要依赖于某个图像实例，所以对整个batchsize数据进行归一化是不合适的，因而提出了IN只对HW维度进行归一化。
      2. 在图像风格化任务中，更合适使用IN来做规范化。
      3. IN只对W,H维度求均值方差进行归一化。
   4. Group Normalization（GN）
      1. BN依赖大batchsize，LN虽然不依赖batchsize，但是在CNN中直接对当前层所有通道数据进行规范化也不太好。
      2. GN先对通道进行分组，每个组内的所有C_i,W,H维度求均值方差进行规范化，也与batchsize无关。
4. 什么是局部最小值？
   1. 梯度为零。
   2. 二阶导数大于0
5. 为什么模型越复杂，越不容易陷入局部最小值?
   1. 比如加入动量的梯度下降，在梯度下降后期陷入局部最小值的时候，有可能借助之前相同的动量越出局部最小值。
6. 小样本该怎么训练？
   1. 数据增强
   2. FocalLoss


## 面试问题（牛客网）
1. 进程
   1. 进程的优点
      1. 顺序程序的特点：具有封闭性和可再现性；
      2. 程序的并发执行和资源共享。多道程序设计出现后，实现了程序的并发执行和资源共享，提高了系统的效率和系统的资源利用率。
   2. 进程的缺点
   3. 操作系统调度切换多个线程要比切换调度进程在速度上快的多。而且进程间内存无法共享，通讯也比较麻烦。
   4. 线程之间由于共享进程内存空间，所以交换数据非常方便；在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。
2. 线程
   1. 线程的优点
      1. 它是一种非常”节俭”的多任务操作方式。在Linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种”昂贵”的多任务工作方式。而运行于一个进程中的多个线程，它们彼此之间使用相同的地址空间，共享大部分数据，启动一个线程所花费的空间远远小于启动一个进程所花费的空间，而且，线程间彼此切换所需的时间也远远小于进程间切换所需要的时间。当然，在具体的系统上，这个数据可能会有较大的区别；
      2. 线程间方便的通信机制，由于同一进程下的线程之间共享数据空间，所以一个线程的数据可以直接为其它线程所用，这不仅快捷，而且方便；
      3. 使多CPU系统更加有效。操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上；
   2. 线程的缺点
      1. 调度时, 要保存线程状态，频繁调度, 需要占用大量的机时；
      2. 程序设计上容易出错（线程同步问题）。
3. 死锁原因
   1. 死锁是指两个或以上进程因竞争临界资源而造成的一种僵局，即一个进程等待一个已经被占用且永不释放的资源。 若无外力作用，这些进程都无法向前推进。 产生死锁的根本原因是系统能够提供的资源个数比要求该资源的进程数要少



