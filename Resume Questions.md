# Resume Question

## SQL
1. 选择--Select
   1. 表连接--想要的数据在多张表里，想取多个字段
   ```
    -- table_1中有id,age; table_2中有id，sex。想取出id,age,sex 三列信息
    -- 将table_1,table_2 根据主键id连接起来
    select a.id,a.age,b.sex from 
    (select id,age from table_1) a --将select之后的内容存为临时表a
    join 
    (select id, sex from table_2) b --将select之后的内容存为临时表b
    on a.id =b.id
   ```
2. 表连接--Join,Left join, right join, union
   1. join : hive的join默认是inner join，找出左右都可匹配的记录；
   2. left join: 左连接，以左表为准，逐条去右表找可匹配字段，如果有多条会逐次列出，如果没有找到则是NULL；
   3. right join：右连接，以右表为准，逐条去左表找可匹配字段，如果有多条会逐次列出，如果没有找到则是NULL；
   4. full outer join: 全连接，包含两个表的连接结果，如果左表缺失或者右表缺失的数据会填充NULL。
   5. 每种join 都有on , on的是左表和右表中都有的字段。join 之前要确保关联键是否去重，是不是刻意保留非去重结果。


3. 去重--distinct
4. 聚合函数和group by
   1. 聚合函数帮助我们进行基本的数据统计，例如计算最大值、最小值、平均值、总数、求和
5. 筛选--having, where
6. 聚合--max, min, sum, count+group by
7. 排序--order by, sort by
8. 条件--case when...end
9.  字符串--substr, concat, split
10. 日期函数--to_date, datediff
11. 分组排序--row_number()
    1.  分组排序 
    2.  rank(), dense_rank()。
    3.  rank()排序相同时会重复，总数不会变 ，意思是会出现1、1、3这样的排序结果；
    4.  dense_rank() 排序相同时会重复，总数会减少，意思是会出现1、1、2这样的排序结果。
    5. row_number() 则在排序相同时不重复，会根据顺序排序。  
12. 取百分比--percentile

Reference: https://zhuanlan.zhihu.com/p/61805956

## Bert
1. 整体架构
   1. 基础架构-tranformer的encoder
      1. Encode可以分为3个部分，输入部分，注意力机制，前馈神经网络
      2. Bert使用多个encoder堆叠在一起，bert base使用12层，bert launch使用24层encoder
      3. 6个encoder堆叠形成编码端，6个decoder堆叠形成解码端
      4. word embedding使用随机初始化或者word_to_vertex
      5. position encoding中使用token embedding+segement emb+position emb
2. 

## Machine Learning


## Machine Learning高频面试题
Reference: https://www.dataapplab.com/machine-learning-interview-questions/
1.  什么是偏差（bias）、方差（variable）之间的均衡？
    1.  Bias 是由于你使用的学习算法过度简单地拟合结果或者错误地拟合结果导致的错误。它反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，即算法本身的拟合能力。Bias 可能会导致模型欠拟合，使其难以具有较高的预测准确性，也很难将你的知识从训练集推广到测试集。
    2.  Variance 是由于你使用的学习算法过于复杂而产生的错误。它反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。反应预测的波动情况。Variance 过高会导致算法对训练数据的高纬度变化过于敏感，这样会导致模型过度拟合数据。从而你的模型会从训练集里带来太多噪音，这会对测试数据有一定的好处。
    3.  Bias-Variance 的分解，本质上是通过在基础数据集中添加偏差、方差和一点由噪声引起的不可约误差，来分解算法上的学习误差。从本质上讲，如果你使模型更复杂并添加更多变量，你将会失去一些 Bias 但获得一些 Variance，这就是我们所说的权衡（tradeoff）。这也是为什么我们在建模的过程中，不希望这个模型同时拥有高的偏差和方差。
   
2. 监督学习和非监督学习有什么不同？
   1. 监督学习需要train有label的数据。例如，为了进行classification（一项受监督的学习任务），您需要首先标记将用于培训模型的数据，以便将数据分类到标记的组中。相反的，无监督学习不需要明确标记数据。

3. KNN和 k-means 聚类由什么不同？
   1. K-Nearest Neighbors是一种监督分类算法，而 k-means聚类是一种无监督的聚类算法。 虽然这些机制起初可能看起来相似，但这实际上意味着为了使K-Nearest Neighbors工作，你需要标记数据，以便将未标记的点分类（因此是最近邻居部分）。 K均值聚类仅需要一组未标记的点和阈值：算法将采用未标记的点并逐渐学习如何通过计算不同点之间的距离的平均值将它们聚类成组。
   2. 这里的关键区别在于，KNN需要标记点，因此是有监督的学习，而k-means不是，因此是无监督学习。

4. 解释一下ROC曲线的原理
   1. ROC曲线是真阳率与各种阈值下的假阳率之间的对比度的图形表示。 它通常用作代表模型灵敏度（真阳性）与跌落之间的平衡或它将触发误报（假阳性）的概率。
5. 定义精度和召回率
   1. 召回（率）也称为真阳性率：您的模型声称的阳性数量与整个数据中的实际阳性数量相比。 精确度也称为阳性预测值，它衡量的是您的模型声称与实际声称的阳性数量相比的准确阳性数量。 在您预测在10个苹果的情况下有10个苹果和5个橙子的情况下，可以更容易地想到回忆和精确度。 你有完美的召回（实际上有10个苹果，你预测会有10个），但66.7％的精度，因为在你预测的15个事件中，只有10个（苹果）是正确的。
6. 什么是贝叶斯定理？它在机器学习环境中如何有用?
   1. 贝叶斯定理描述了当你不能准确知悉一个事物的本质时，你可以依靠与事物特定本质相关的事件出现的多少去判断其本质属性的概率。 它给出了已知先验知识下事件的后验概率。
   2. 在数学上，它表示为条件样本的真阳性率除以总体的假阳性率和条件的真阳性率之和。假设你在流感测试后有60%的机会真的感染了流感，但是在感染了流感的人中，50%的测试都是错误的，总人口只有5%的机会感染了流感。在做了阳性测试后，你真的有60%的机会患上流感吗？
   3. 贝叶斯定理说不，它说你有一个（0.6*0.05）（条件样本的真阳性率）/（0.6*0.05）（条件样本的真阳性率）+（0.5*0.95）（人群的假阳性率）= 5.94%的机会感染流感。
7. 为什么我们要称“朴素”贝叶斯？
   1. 尽管 Naive Bayes 具有实际应用，特别是在文本挖掘中，但它被认为是“天真的”，因为它假设在实际数据中几乎不可能看到：条件概率被计算为组件个体概率的纯乘积。 这意味着特征的绝对独立性 – 这种情况在现实生活中可能永远不会遇到。





